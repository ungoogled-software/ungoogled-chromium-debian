--- a/media/filters/vpx_video_decoder.cc
+++ b/media/filters/vpx_video_decoder.cc
@@ -242,13 +242,6 @@
       return false;
     }
 
-    vpx_codec_err_t status =
-        vpx_codec_control(vpx_codec_.get(), VP9D_SET_LOOP_FILTER_OPT, 1);
-    if (status != VPX_CODEC_OK) {
-      DLOG(ERROR) << "Failed to enable VP9D_SET_LOOP_FILTER_OPT. "
-                  << vpx_codec_error(vpx_codec_.get());
-      return false;
-    }
   }
 
   if (config.alpha_mode() == VideoDecoderConfig::AlphaMode::kIsOpaque)
--- a/third_party/blink/renderer/modules/mediarecorder/vpx_encoder.cc
+++ b/third_party/blink/renderer/modules/mediarecorder/vpx_encoder.cc
@@ -72,14 +72,6 @@
   TRACE_EVENT0("media", "VpxEncoder::EncodeOnEncodingTaskRunner");
   DCHECK_CALLED_ON_VALID_SEQUENCE(encoding_sequence_checker_);
 
-  if (frame->format() == media::PIXEL_FORMAT_NV12 &&
-      frame->storage_type() == media::VideoFrame::STORAGE_GPU_MEMORY_BUFFER)
-    frame = WrapMappedGpuMemoryBufferVideoFrame(frame);
-  if (!frame) {
-    LOG(WARNING) << "Invalid video frame to encode";
-    return;
-  }
-
   const gfx::Size frame_size = frame->visible_rect().size();
   base::TimeDelta duration = EstimateFrameDuration(*frame);
   const media::WebmMuxer::VideoParameters video_params(frame);
@@ -95,18 +87,6 @@
   std::string data;
   std::string alpha_data;
   switch (frame->format()) {
-    case media::PIXEL_FORMAT_NV12: {
-      last_frame_had_alpha_ = false;
-      DoEncode(encoder_.get(), frame_size, frame->data(VideoFrame::kYPlane),
-               frame->visible_data(VideoFrame::kYPlane),
-               frame->stride(VideoFrame::kYPlane),
-               frame->visible_data(VideoFrame::kUVPlane),
-               frame->stride(VideoFrame::kUVPlane),
-               frame->visible_data(VideoFrame::kUVPlane) + 1,
-               frame->stride(VideoFrame::kUVPlane), duration, force_keyframe,
-               data, &keyframe, VPX_IMG_FMT_NV12);
-      break;
-    }
     case media::PIXEL_FORMAT_I420: {
       last_frame_had_alpha_ = false;
       DoEncode(encoder_.get(), frame_size, frame->data(VideoFrame::kYPlane),
@@ -195,7 +175,7 @@
                           bool* const keyframe,
                           vpx_img_fmt_t img_fmt) {
   DCHECK_CALLED_ON_VALID_SEQUENCE(encoding_sequence_checker_);
-  DCHECK(img_fmt == VPX_IMG_FMT_I420 || img_fmt == VPX_IMG_FMT_NV12);
+  DCHECK(img_fmt == VPX_IMG_FMT_I420);
 
   vpx_image_t vpx_image;
   vpx_image_t* const result =
--- a/third_party/webrtc/modules/video_coding/codecs/vp8/libvpx_vp8_encoder.cc
+++ b/third_party/webrtc/modules/video_coding/codecs/vp8/libvpx_vp8_encoder.cc
@@ -954,9 +954,6 @@
     case VideoFrameBuffer::Type::kI420:
       PrepareI420Image(input_image->GetI420());
       break;
-    case VideoFrameBuffer::Type::kNV12:
-      PrepareNV12Image(input_image->GetNV12());
-      break;
     default: {
       rtc::scoped_refptr<I420BufferInterface> i420_image =
           input_image->ToI420();
@@ -1240,8 +1237,6 @@
         << "Not all raw images had the right format!";
     return;
   }
-  RTC_LOG(INFO) << "Updating vp8 encoder pixel format to "
-                << (fmt == VPX_IMG_FMT_NV12 ? "NV12" : "I420");
   for (size_t i = 0; i < raw_images_.size(); ++i) {
     vpx_image_t& img = raw_images_[i];
     auto d_w = img.d_w;
@@ -1288,7 +1283,6 @@
 
 void LibvpxVp8Encoder::PrepareNV12Image(const NV12BufferInterface* frame) {
   RTC_DCHECK(!raw_images_.empty());
-  MaybeUpdatePixelFormat(VPX_IMG_FMT_NV12);
   // Image in vpx_image_t format.
   // Input image is const. VP8's raw image is not defined as const.
   raw_images_[0].planes[VPX_PLANE_Y] = const_cast<uint8_t*>(frame->DataY());
--- a/third_party/webrtc/modules/video_coding/codecs/vp9/vp9_impl.cc
+++ b/third_party/webrtc/modules/video_coding/codecs/vp9/vp9_impl.cc
@@ -216,39 +216,6 @@
   return scalability_structure_controller;
 }
 
-vpx_svc_ref_frame_config_t Vp9References(
-    rtc::ArrayView<const ScalableVideoController::LayerFrameConfig> layers) {
-  vpx_svc_ref_frame_config_t ref_config = {};
-  for (const ScalableVideoController::LayerFrameConfig& layer_frame : layers) {
-    const auto& buffers = layer_frame.Buffers();
-    RTC_DCHECK_LE(buffers.size(), 3);
-    int sid = layer_frame.SpatialId();
-    if (!buffers.empty()) {
-      ref_config.lst_fb_idx[sid] = buffers[0].id;
-      ref_config.reference_last[sid] = buffers[0].referenced;
-      if (buffers[0].updated) {
-        ref_config.update_buffer_slot[sid] |= (1 << buffers[0].id);
-      }
-    }
-    if (buffers.size() > 1) {
-      ref_config.gld_fb_idx[sid] = buffers[1].id;
-      ref_config.reference_golden[sid] = buffers[1].referenced;
-      if (buffers[1].updated) {
-        ref_config.update_buffer_slot[sid] |= (1 << buffers[1].id);
-      }
-    }
-    if (buffers.size() > 2) {
-      ref_config.alt_fb_idx[sid] = buffers[2].id;
-      ref_config.reference_alt_ref[sid] = buffers[2].referenced;
-      if (buffers[2].updated) {
-        ref_config.update_buffer_slot[sid] |= (1 << buffers[2].id);
-      }
-    }
-  }
-  // TODO(bugs.webrtc.org/11999): Fill ref_config.duration
-  return ref_config;
-}
-
 }  // namespace
 
 void VP9EncoderImpl::EncoderOutputCodedPacketCallback(vpx_codec_cx_pkt* pkt,
@@ -455,15 +422,6 @@
     }
   }
 
-  if (higher_layers_enabled && !force_key_frame_) {
-    // Prohibit drop of all layers for the next frame, so newly enabled
-    // layer would have a valid spatial reference.
-    for (size_t i = 0; i < num_spatial_layers_; ++i) {
-      svc_drop_frame_.framedrop_thresh[i] = 0;
-    }
-    force_all_active_layers_ = true;
-  }
-
   if (svc_controller_) {
     VideoBitrateAllocation allocation;
     for (int sid = 0; sid < num_spatial_layers_; ++sid) {
@@ -819,7 +777,6 @@
                     inst->VP9().adaptiveQpMode ? 3 : 0);
 
   vpx_codec_control(encoder_, VP9E_SET_FRAME_PARALLEL_DECODING, 0);
-  vpx_codec_control(encoder_, VP9E_SET_SVC_GF_TEMPORAL_REF, 0);
 
   if (is_svc_) {
     vpx_codec_control(encoder_, VP9E_SET_SVC, 1);
@@ -831,56 +788,6 @@
         performance_flags_by_spatial_index_.rbegin()->base_layer_speed);
   }
 
-  if (num_spatial_layers_ > 1) {
-    switch (inter_layer_pred_) {
-      case InterLayerPredMode::kOn:
-        vpx_codec_control(encoder_, VP9E_SET_SVC_INTER_LAYER_PRED, 0);
-        break;
-      case InterLayerPredMode::kOff:
-        vpx_codec_control(encoder_, VP9E_SET_SVC_INTER_LAYER_PRED, 1);
-        break;
-      case InterLayerPredMode::kOnKeyPic:
-        vpx_codec_control(encoder_, VP9E_SET_SVC_INTER_LAYER_PRED, 2);
-        break;
-      default:
-        RTC_NOTREACHED();
-    }
-
-    memset(&svc_drop_frame_, 0, sizeof(svc_drop_frame_));
-    const bool reverse_constrained_drop_mode =
-        inter_layer_pred_ == InterLayerPredMode::kOn &&
-        codec_.mode == VideoCodecMode::kScreensharing &&
-        num_spatial_layers_ > 1;
-    if (reverse_constrained_drop_mode) {
-      // Screenshare dropping mode: drop a layer only together with all lower
-      // layers. This ensures that drops on lower layers won't reduce frame-rate
-      // for higher layers and reference structure is RTP-compatible.
-      svc_drop_frame_.framedrop_mode = CONSTRAINED_FROM_ABOVE_DROP;
-      svc_drop_frame_.max_consec_drop = 5;
-      for (size_t i = 0; i < num_spatial_layers_; ++i) {
-        svc_drop_frame_.framedrop_thresh[i] = config_->rc_dropframe_thresh;
-      }
-      // No buffering is needed because the highest layer is always present in
-      // all frames in CONSTRAINED_FROM_ABOVE drop mode.
-      layer_buffering_ = false;
-    } else {
-      // Configure encoder to drop entire superframe whenever it needs to drop
-      // a layer. This mode is preferred over per-layer dropping which causes
-      // quality flickering and is not compatible with RTP non-flexible mode.
-      svc_drop_frame_.framedrop_mode =
-          full_superframe_drop_ ? FULL_SUPERFRAME_DROP : CONSTRAINED_LAYER_DROP;
-      // Buffering is needed only for constrained layer drop, as it's not clear
-      // which frame is the last.
-      layer_buffering_ = !full_superframe_drop_;
-      svc_drop_frame_.max_consec_drop = std::numeric_limits<int>::max();
-      for (size_t i = 0; i < num_spatial_layers_; ++i) {
-        svc_drop_frame_.framedrop_thresh[i] = config_->rc_dropframe_thresh;
-      }
-    }
-    vpx_codec_control(encoder_, VP9E_SET_SVC_FRAME_DROP_LAYER,
-                      &svc_drop_frame_);
-  }
-
   // Register callback for getting each spatial layer.
   vpx_codec_priv_output_cx_pkt_cb_pair_t cbp = {
       VP9EncoderImpl::EncoderOutputCodedPacketCallback,
@@ -1023,52 +930,10 @@
     }
   }
 
-  // Need to set temporal layer id on ALL layers, even disabled ones.
-  // Otherwise libvpx might produce frames on a disabled layer:
-  // http://crbug.com/1051476
-  for (int sl_idx = 0; sl_idx < num_spatial_layers_; ++sl_idx) {
-    layer_id.temporal_layer_id_per_spatial[sl_idx] = layer_id.temporal_layer_id;
-  }
-
   if (layer_id.spatial_layer_id < first_active_layer_) {
     layer_id.spatial_layer_id = first_active_layer_;
   }
 
-  if (svc_controller_) {
-    layer_id.spatial_layer_id = layer_frames_.front().SpatialId();
-    layer_id.temporal_layer_id = layer_frames_.front().TemporalId();
-    for (const auto& layer : layer_frames_) {
-      layer_id.temporal_layer_id_per_spatial[layer.SpatialId()] =
-          layer.TemporalId();
-    }
-  }
-
-  if (is_svc_ && performance_flags_.use_per_layer_speed) {
-    // Update speed settings that might depend on temporal index.
-    bool speed_updated = false;
-    for (int sl_idx = 0; sl_idx < num_spatial_layers_; ++sl_idx) {
-      const int target_speed =
-          layer_id.temporal_layer_id_per_spatial[sl_idx] == 0
-              ? performance_flags_by_spatial_index_[sl_idx].base_layer_speed
-              : performance_flags_by_spatial_index_[sl_idx].high_layer_speed;
-      if (svc_params_.speed_per_layer[sl_idx] != target_speed) {
-        svc_params_.speed_per_layer[sl_idx] = target_speed;
-        speed_updated = true;
-      }
-    }
-    if (speed_updated) {
-      vpx_codec_control(encoder_, VP9E_SET_SVC_PARAMETERS, &svc_params_);
-    }
-  }
-
-  vpx_codec_control(encoder_, VP9E_SET_SVC_LAYER_ID, &layer_id);
-
-  if (num_spatial_layers_ > 1) {
-    // Update frame dropping settings as they may change on per-frame basis.
-    vpx_codec_control(encoder_, VP9E_SET_SVC_FRAME_DROP_LAYER,
-                      &svc_drop_frame_);
-  }
-
   if (config_changed_) {
     if (vpx_codec_enc_config_set(encoder_, config_)) {
       return WEBRTC_VIDEO_CODEC_ERROR;
@@ -1110,19 +975,7 @@
   rtc::scoped_refptr<const I010BufferInterface> i010_copy;
   switch (profile_) {
     case VP9Profile::kProfile0: {
-      if (input_image.video_frame_buffer()->type() ==
-          VideoFrameBuffer::Type::kNV12) {
-        const NV12BufferInterface* nv12_buffer =
-            input_image.video_frame_buffer()->GetNV12();
-        video_frame_buffer = nv12_buffer;
-        MaybeRewrapRawWithFormat(VPX_IMG_FMT_NV12);
-        raw_->planes[VPX_PLANE_Y] = const_cast<uint8_t*>(nv12_buffer->DataY());
-        raw_->planes[VPX_PLANE_U] = const_cast<uint8_t*>(nv12_buffer->DataUV());
-        raw_->planes[VPX_PLANE_V] = raw_->planes[VPX_PLANE_U] + 1;
-        raw_->stride[VPX_PLANE_Y] = nv12_buffer->StrideY();
-        raw_->stride[VPX_PLANE_U] = nv12_buffer->StrideUV();
-        raw_->stride[VPX_PLANE_V] = nv12_buffer->StrideUV();
-      } else {
+      if (true) {
         rtc::scoped_refptr<I420BufferInterface> i420_buffer =
             input_image.video_frame_buffer()->ToI420();
         video_frame_buffer = i420_buffer;
@@ -1174,24 +1027,6 @@
     flags = VPX_EFLAG_FORCE_KF;
   }
 
-  if (svc_controller_) {
-    vpx_svc_ref_frame_config_t ref_config = Vp9References(layer_frames_);
-    vpx_codec_control(encoder_, VP9E_SET_SVC_REF_FRAME_CONFIG, &ref_config);
-  } else if (external_ref_control_) {
-    vpx_svc_ref_frame_config_t ref_config =
-        SetReferences(force_key_frame_, layer_id.spatial_layer_id);
-
-    if (VideoCodecMode::kScreensharing == codec_.mode) {
-      for (uint8_t sl_idx = 0; sl_idx < num_active_spatial_layers_; ++sl_idx) {
-        ref_config.duration[sl_idx] = static_cast<int64_t>(
-            90000 / (std::min(static_cast<float>(codec_.maxFramerate),
-                              framerate_controller_[sl_idx].GetTargetRate())));
-      }
-    }
-
-    vpx_codec_control(encoder_, VP9E_SET_SVC_REF_FRAME_CONFIG, &ref_config);
-  }
-
   first_frame_in_picture_ = true;
 
   // TODO(ssilkin): Frame duration should be specified per spatial layer
@@ -1298,11 +1133,7 @@
   vp9_info->first_active_layer = first_active_layer_;
 
   vp9_info->num_ref_pics = 0;
-  FillReferenceIndices(pkt, pics_since_key_, vp9_info->inter_layer_predicted,
-                       vp9_info);
-  if (vp9_info->flexible_mode) {
-    vp9_info->gof_idx = kNoGofIdx;
-  } else {
+  if (true) {
     vp9_info->gof_idx =
         static_cast<uint8_t>(pics_since_key_ % gof_.num_frames_in_gof);
     vp9_info->temporal_up_switch = gof_.temporal_up_switch[vp9_info->gof_idx];
@@ -1370,6 +1201,7 @@
   }
 }
 
+/*
 void VP9EncoderImpl::FillReferenceIndices(const vpx_codec_cx_pkt& pkt,
                                           const size_t pic_num,
                                           const bool inter_layer_predicted,
@@ -1622,6 +1454,7 @@
 
   return ref_config;
 }
+*/
 
 int VP9EncoderImpl::GetEncodedLayerFrame(const vpx_codec_cx_pkt* pkt) {
   RTC_DCHECK_EQ(pkt->kind, VPX_CODEC_CX_FRAME_PKT);
@@ -1663,14 +1496,10 @@
                         input_image_->timestamp());
   encoded_image_.SetSpatialIndex(spatial_index);
 
-  UpdateReferenceBuffers(*pkt, pics_since_key_);
-
   TRACE_COUNTER1("webrtc", "EncodedFrameSize", encoded_image_.size());
   encoded_image_.SetTimestamp(input_image_->timestamp());
-  encoded_image_._encodedHeight =
-      pkt->data.frame.height[layer_id.spatial_layer_id];
-  encoded_image_._encodedWidth =
-      pkt->data.frame.width[layer_id.spatial_layer_id];
+  encoded_image_._encodedHeight = raw_->d_h;
+  encoded_image_._encodedWidth = raw_->d_w;
   int qp = -1;
   vpx_codec_control(encoder_, VP8E_GET_LAST_QUANTIZER, &qp);
   encoded_image_.qp_ = qp;
@@ -1686,14 +1515,6 @@
 
 void VP9EncoderImpl::DeliverBufferedFrame(bool end_of_picture) {
   if (encoded_image_.size() > 0) {
-    if (num_spatial_layers_ > 1) {
-      // Restore frame dropping settings, as dropping may be temporary forbidden
-      // due to dynamically enabled layers.
-      for (size_t i = 0; i < num_spatial_layers_; ++i) {
-        svc_drop_frame_.framedrop_thresh[i] = config_->rc_dropframe_thresh;
-      }
-    }
-
     codec_specific_.end_of_picture = end_of_picture;
 
     encoded_complete_callback_->OnEncodedImage(encoded_image_,
@@ -1929,8 +1750,6 @@
   if (!raw_) {
     raw_ = vpx_img_wrap(nullptr, fmt, codec_.width, codec_.height, 1, nullptr);
   } else if (raw_->fmt != fmt) {
-    RTC_LOG(INFO) << "Switching VP9 encoder pixel format to "
-                  << (fmt == VPX_IMG_FMT_NV12 ? "NV12" : "I420");
     vpx_img_free(raw_);
     raw_ = vpx_img_wrap(nullptr, fmt, codec_.width, codec_.height, 1, nullptr);
   }
@@ -2026,14 +1845,6 @@
     }
   }
 
-  vpx_codec_err_t status =
-      vpx_codec_control(decoder_, VP9D_SET_LOOP_FILTER_OPT, 1);
-  if (status != VPX_CODEC_OK) {
-    RTC_LOG(LS_ERROR) << "Failed to enable VP9D_SET_LOOP_FILTER_OPT. "
-                      << vpx_codec_error(decoder_);
-    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
-  }
-
   return WEBRTC_VIDEO_CODEC_OK;
 }
 
--- a/third_party/webrtc/modules/video_coding/codecs/vp9/vp9_impl.h
+++ b/third_party/webrtc/modules/video_coding/codecs/vp9/vp9_impl.h
@@ -133,7 +133,6 @@
   const bool trusted_rate_controller_;
   bool layer_buffering_;
   const bool full_superframe_drop_;
-  vpx_svc_frame_drop_t svc_drop_frame_;
   bool first_frame_in_picture_;
   VideoBitrateAllocation current_bitrate_allocation_;
   bool ss_info_needed_;
